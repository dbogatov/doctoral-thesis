\subsection{Logarithmic-BRC}

	\textcite{practical-range-search} introduced a novel protocol called ``Logarithmic-BRC'' whose \acrshort{io} complexity depends only on the result size, regardless of the database size.
	The core primitive for their construction is a \acrfull{sse} scheme.
	An \acrshort{sse} scheme is a server-client protocol in which the server stores a specially encrypted keywords-to-documents map, and a client can query documents with keywords while the server
	learns neither keywords nor the documents.
	Note that the map stores short document identifiers instead of the actual documents, and we will use the term ``documents'' to mean ``document identifiers'' or ``record IDs'' in this section.

	The construction treats record values as documents and index ranges as keywords so that records can be retrieved by the ranges that include them.
	Specifically, a client builds a virtual binary tree over the domain of indices and assigns each record a set of keywords, which is the path from that record to the root.
	This way, the root keyword is associated with all documents and the leaf keyword is associated with only one record.

	Upon query, a client computes a cover --- a set of nodes whose sub-trees cover the requested range.
	A client sends these keywords to the \acrshort{sse} server, which returns encrypted documents --- result values.
	Of the several covering techniques suggested in the protocol \cite{practical-range-search} we have chosen the \acrfull{brc}, because it results in fewest nodes and does not return false-positives.
	\textcite{brc} have proven that the worst-case number of nodes for domain of size $N$ is $\bigO{\log N}$ and presented an efficient \acrshort{brc} algorithm.

	\subsubsection{Security}

		In a snapshot setting, this construction's security is that of the \acrshort{sse}.
		We have used \cite{cjjkrs-13} and \cite{cjjjkrs-14} \acrshort{sse} schemes; their leakage in a snapshot setting is the database size and at most some initialization parameters.
		Thus, the security of these schemes is high enough to call them \emph{fully hiding} in our setting.
		Additional access pattern leakage comes up during queries; exact implications of this leakage remain an open research problem but it is known that it can be harmful \cite{generic-attacks-kellaris}.

	\subsubsection{Analysis and implementation challenges}

		Communication involves a client sending at worst $\log_2 N$ keywords and server responding with the exact result.

		For each keyword in the query set, server will query the \acrshort{sse} scheme, which will return $r$ documents.
		Therefore, server's \acrshort{io} complexity is that of \acrshort{sse}.

		\textcite{practical-range-search} have used \cite{cjjkrs-13} \acrshort{sse} scheme in their implementation, but we have found it slow it terms of \acrshort{io}.
		Instead, we have implemented an improved scheme \cite{cjjjkrs-14}, which directly addresses \acrshort{io} optimization.

		Both \acrshort{sse} schemes' \acrshort{io} complexity is linear with the result size $r$.
		\cite{cjjjkrs-14} scheme makes at most one \acrshort{io} per result document in the worst-case and there are extensions to significantly improve \acrshort{io} complexity. % chktex 2
		We have implemented the \texttt{pack} extension, which packs documents in blocks to fit the \acrshort{io} pages.
		We note that this extension can dramatically reduce the \acrshortpl{io} (see \cref{section:range-snapshot:results-protocols} and \cref{figure:protocols-query-sizes}).

		Logarithmic-BRC is very scalable as its performance does not depend on total data size and only degrades with the result size.
		Storage overhead, however, is significant.
		Each record is associated with the whole path in the binary tree --- $\log_2 N$ nodes (keywords).
		The storage complexity is therefore $\bigO{N \log N}$, and the overhead is then a factor of $\log N$.

		Updates, while addressed in the original protocol, are not very practical in this construction.
		Authors suggest using bulk-loading for updates, maintaining merge trees, and requiring the client to do a merge once in a while.
		The \acrshort{io} complexity of such approach is unclear.
		In our implementation we perform the construction stage only in batch mode, and thus do not include it in the analysis.
		We also emphasize that the update routine was not implemented for evaluation in the original paper.
