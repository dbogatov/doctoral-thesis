\subsection{POPE}

	\textcite{pope} presented a protocol, direct improvement over mOPE \cite{ope-ideal-security-protocol}, which is especially suitable for large number of insertions and small number of queries.
	The construction is heavily based on buffer trees \cite{buffer-tree} to support fast insertion and lazy sorting.

	The idea is to maintain a POPE tree on the server and have the client manipulate that tree.
	POPE tree is similar to B-tree, in that the nodes have multiple children and nodes are sorted on each level.
	Each node has an ordered list of \emph{labels} of size $L$ and an unbounded unsorted set of encrypted data called buffer.
	Parameter $L$ controls the list size, the leaf's buffer size, and the size of client's working set.
	The insertion procedure simply adds an encrypted piece of data to the root's buffer, thus we do not concentrate on insertion analysis in this section.

	The query procedure is more complex.
	To answer a query, the server interacts with the client to split the tree according to the query endpoints.
	On a high level, for each endpoint the buffers are cleared (content pushed down to leaves), and nodes in the paths are split.
	After that, answering a query means replying with all ciphertexts in all buffers between the two endpoint leaves.

	The authors provide cost analysis of their construction.
	Search operations are expected to require $\bigO{\log_L n}$ rounds.
	It must be noted that the first queries will require many more rounds, since large buffers must be sorted.

	\subsubsection{Security}
		This construction satisfies the security definition of frequency\hyp{}hiding partial order-preserving (FH-POP) protocol (introduced in the paper \cite{pope}).
		According to \cite[Theorem~3]{pope}, after $n$ insertions and $m$ queries with local storage of size $L$, where $m L \in o(n)$, the POPE scheme is frequency-hiding partial order-preserving with $\bigOmega{ \frac{n^2}{mL \log_L n} - n }$ incomparable pairs of elements. % chktex 2
		Simply put, the construction leaks pairwise order of a \emph{bounded} number of elements.
		Aside from this, the construction provably hides the frequency (i.e.\ equality) of the elements.

	\subsubsection{Analysis and implementation challenges}

		In our analysis we count each request-response communication as a round.
		This is different from \cite{pope} where they use \emph{streaming} a number of elements as a single round. % chktex 2
		The rationale for our approach is that if we allow persistent channels additionally to messages, then any protocol can open a channel for each operation.
		Thus, we do not allow channels for all protocols in our analysis.

		Also, as noted by the authors, if $L = n^{\epsilon}$ for $0 < \epsilon < 1$, then the amortized costs become $\bigO{1}$.
		While this is true, in our analysis the choice of $L$ depends on the storage volume block size for {\IO} optimizations, instead of the client's volatile storage capacity.
		Thus, the costs remain logarithmic.

		Search bandwidth depends heavily on the current state of the tree.
		When the tree is completely unsorted (the first query), all elements of the tree will be transferred to split the large root, then possibly internal node will have to be split requiring sending of $\frac{N}{L}$ elements, and so on, thus $\bigO{N + r}$.
		When the tree is completely sorted (after a large number of uniform queries), the bandwidth will be similar to that of a standard {\BPlus} tree --- $\bigO{L \log_L N + r}$.
		The average case is hard to compute; however, authors prove an upper bound on bandwidth after $n$ insertions and $m$ queries --- $\bigO{m L \log_L n + n \log_L m + n \log_L (\lg n) }$.

		POPE tree is not optimized for {\IO} the way B-tree is.
		Search complexity is hard to analyze as is bandwidth complexity.
		In the worst-case (first query), all blocks need to be accessed $\bigO{\frac{N}{B} + \frac{r}{B}}$.
		In the best-case all nodes occupy exactly one block and {\IO} complexity is the same as with {\BPlus} tree $\bigO{\log_L \frac{N}{B} + \frac{r}{B}}$.
		The average case is in between and matters get worse as the node is not guaranteed to occupy a single block due to the buffers of arbitrary size.

		Client's persistent storage is negligibly small --- it stores the encryption key.
		Volatile storage is bounded by $L$.

		For practitioners we present a number of things to consider.
		Buffer within one node is unsorted, so in the worst-case, $L$-sized chunks remain unordered.
		Due to this property, the query result may contain up to $2 (L - 1)$ extra entries, which the client will have to discard from the response.

		The first query after a large number of insertions will result in client sorting the whole $N$ elements, and thus, POPE has different performance for cold and warm start.
		Also, even to navigate an already structured tree, the server has to send to the client the whole $L$ elements and ask where to go on all levels.

		Furthermore, \cite{pope} does not stress the fact that after alternating insertions and queries, it may happen that some intermediate buffers are not empty, thus returning buffers between endpoints must include intermediate buffers as well. % chktex 2
		The consequence is that the whole subtree is traversed between paths to endpoints, unlike the {\BPlus} tree case where only leaves are involved.

		Finally, POPE tree is not optimized for {\IO} operations.
		Even if $L$ is chosen so that the node fits in the block, only leaves and only after some number of searches will optimally fit in blocks.
		Arbitrary sized buffers of intermediate nodes and the lack of underflow requirement do not allow for {\IO} optimization.
