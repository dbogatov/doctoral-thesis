\section{Evaluation}\label{section:range-snapshot:evaluation}

	All experiments were conducted on a single machine.
	We use macOS 10.14.2 with 8-Core \SI{3.2}{\giga\hertz} Intel Xeon W processor, \SI{32}{\giga\byte} DDR4 ECC main memory and \SI{1}{\tera\byte} \acrshort{ssd} disk.
	The main code is written in {\Csharp} and runs on {.NET Core 2.1.3}.

	\subsubsection*{Interactive website}\label{section:range-snapshot:website}

		Additionally to making our source code, compiled binaries and Docker images available, we want to let researchers interactively run small-sized simulations.
		We host a website \cite{ore-website} where one can select a protocol (including baselines, CLOZ \cite{parameter-hiding-ore} and both \acrshort{sse} schemes), cache size and policy and \acrshort{io} page parameter; supply one's own data and query sets, and run the simulations.
		Simulations are run one at a time and usually complete within seconds.
		The user is then able to view the result --- tables, plots, values and raw logs, which we used to build plots for this paper.
		Input size on the website is limited for practical purposes and users are encouraged to run arbitrary-size simulations using our binaries or Docker images.

	\subsection{Implementation}

		We have implemented most of the primitives, data structures, and constructions ourselves.
		For some primitives and all schemes we provided the first open-sourced cross-platform {\Csharp} implementation.
		We note that neither primitives, nor schemes are production-ready; however, we believe they can be used in research projects and prototypes.
		We also emphasize that the {\BPlus} tree implementation we are using, although our own with instrumentation in it, is not custom in any way, but rather standard as defined in the original paper \cite{b-tree} with deletion algorithm by \cite{b-plus-tree-deletion}.

		This software project (22K lines of code, third of which are tests) is documented and tested (over 97\% coverage).
		All code including primitives, data structures, schemes, protocols, simulation logic, benchmarks, build scripts and tests is published on GitHub \cite{ore-project} under CC BY-NC 4.0 license.
		Additionally, we have published parts of the project as stand-alone {.NET Core} (nuGet) packages, and we host a web-server where users can run simulations for small inputs (see previous subsection).

		\subsubsection{Primitives}

			All schemes and protocols use the same primitives, most of which we implemented ourselves.
			All primitives rely on the default {.NET Core} \acrshort{aes} implementation.
			{.NET Core} uses platform-specific implementation of \acrshort{aes}, thus leverages \texttt{AES-NI} \acrshort{cpu} instruction.
			In our project all key sizes are 128 bits, as is \acrshort{aes} block size.

			We implemented \acrshort{aes}-based \acrshort{prg}, which uses \acrshort{aes} \cite{aes-nist} in CTR mode \cite{nist-modes} and caches unused entropy (as suggested in \cite{aes-ctr-rfc}).
			For \acrshort{prf}, since we need only 128-bit inputs and outputs, we used one application of \acrshort{aes} \cite[Proposition 3.27]{intro-to-modern-crypto}.
			For symmetric encryption we use \acrshort{aes} with a random initialization vector in CBC mode \cite[Section 3.6.2]{intro-to-modern-crypto}.
			For hash we use default {.NET Core} \acrshort{sha}-2 implementation.
			For \acrshort{prp}, we implemented unbalanced Feistel networks \cite{unbalanced-feistel} for large inputs and Knuth shuffle \cite{knuth-shuffle} for small inputs.
			Please see the README of project's repository \cite{ore-project} for low-level details.

			\input{figures/fig-benchmarks}

		\subsubsection{Schemes and protocols}

			We implemented schemes and protocols precisely as in the original papers.
			When we found problems or improvements, we described them in implementation challenges notes, but did not alter the original designs in our code, unless explicitly stated.
			Each \acrshort{ore} scheme implements a {\Csharp} interface; thus our own implementation of {\BPlus} tree operates on a generic \acrshort{ore}.
			For the \emph{no encryption} baseline, we have a stub implementation of the interface, which has identity functions for encryption and decryption.
			It is important to note that all schemes and protocols use exclusively our implementations of primitives.
			Thus we rule out the possible bias of one primitive implementation being faster than the other.

		\subsubsection{Simulations}

			We have four types of simulations.

			Protocol simulation runs both protocol stages --- construction and search --- on supplied data for all protocols including all schemes coupled with {\BPlus} tree.
			In this simulation we measure the primitive usage, number of \acrshort{ore} scheme operations (when applies), communication volume and size, and the number of \acrshort{io} requests.
			We intentionally do not measure elapsed time, since it would be extremely inaccurate in this setting --- simulation and measurement routines take substantial fraction of time.

			Scheme simulation runs all five \acrshort{ore} schemes and tracks only the primitive usage.

			The scheme benchmark, however, is designed to track time.
			We use Benchmark.NET \cite{benchmark-net} to ensure that the reported time is accurate.
			This tool handles issues like cold / warm start, elevating process' priority, and performing enough runs to draw statistically sound conclusions.
			This benchmark reports elapsed time up to nanoseconds for all four schemes (excluding CLOZ \cite{parameter-hiding-ore}) and their variants.

			\input{figures/fig-protocols}

			Finally, primitive benchmark uses the same tool, but compares the primitives.
			We use it to compare different implementations of primitives (e.g.\ Feistel \acrshort{prp} vs pre-generated permutation) and to approximate time consumption of the schemes and protocols based on primitive usage.

	\subsection{Setup}

		For our simulations, we have used three datasets.
		Two synthetic distributions, that are uniform (range is third of data size) and normal (standard deviation is $0.1$ of data size).
		The real dataset is California public employees salaries (``total pay and benefits'' column) \cite{ca-dataset}.
		Synthetic datasets and subsets of the real dataset are generated pseudo\hyp{}randomly.
		Queries are generated uniformly at random with a range as a percentage of data size.

	\subsection{Results}

		\subsubsection{Primitive usage by schemes}\label{section:range-snapshot:schemes-primitive-usage}

			In \cref{table:primitive-usage-theory} we show the simulation-derived values of each \acrshort{ope} and \acrshort{ore} scheme's primitive usage.
			Each scheme is given \num{1000} data points of each dataset.
			First, the scheme encrypts each data point, then decrypts each ciphertext and then performs five comparisons (all possible types) pairwise.
			This micro-simulation is repeated \num{100} times.
			Resulting values for primitive usage are averaged for each scheme.
			State and ciphertext sizes are calculated after each operation and the values are averaged.
			Please note that the simulated values are consistent with the theoretical calculations.

		\subsubsection{Benchmarks of schemes and primitives}

			Using the Benchmark.NET tool \cite{benchmark-net}, we have accurately tracked the performance of the schemes and primitives running of different parameters (see \cref{figure:benchmarks:schemes,figure:benchmarks:primitives}).
			\acrshort{ore} schemes benchmark setup is the same as in primitive usage simulation \cref{section:range-snapshot:schemes-primitive-usage}.
			Primitives were given randomly generated byte inputs and keys of different sizes (e.g.\ \acrshort{prp} of $2$ to $32$ bits).
			Benchmark.NET decides how many times to run the routine to get statistically sound results.
			For example, large variance results in more runs.
			To improve the accuracy, each run is compiled in release mode as a separate project and runs in a separate process with the highest priority.

			Please note the logarithmic scale of the schemes' performances.
			FH-OPE is fast since it does not perform \acrshort{cpu}-heavy operations and works in main memory.
			Lewi-Wu performance degrades exponentially with the increase of block size mainly due to exponential number of \acrshort{prf} executions and the performance of \acrshort{prp} degrading exponentially.
			Note also that Lewi-Wu comparison takes noticeable time due to Hash primitive usage.

			In the primitives benchmark, it is clear that most primitives use \acrshort{aes} under the hood.
			\acrshort{prg} and \acrshort{prf} take less than \acrshort{aes} because they do not include the initialization vector generation needed for symmetric encryption.
			\acrshort{prp} is implemented as a Knuth shuffle \cite{knuth-shuffle} and its complexity is exponential in the input bit length.
			Input size of 2 bits is shown on \cref{figure:benchmarks:schemes}.
			\acrshort{prg} does not discard the entropy generated by \acrshort{aes} cycle, so one \acrshort{aes} cycle can supply four 32-bit integers.
			\acrshort{prp} generates the permutation table once and does not regenerate it if the same key and number of bits are supplied.

		\subsubsection{Protocols}\label{section:range-snapshot:results-protocols}

			In this experiment we have run each protocol with each of the three datasets.
			Dataset sizes are \num{247000} (bounded by California Employees dataset size) and the number of queries is \num{1000}.
			Queries are generated uniformly at random with a fixed range --- \SI{0.5}{\percent} of data size.
			The cache size is fixed to \num{128} blocks, and the {\BPlus} tree branching factor as well as block sizes for other protocols are set such that the page size is \SI{4}{\kibi\byte}.
			The values we are measuring are the number of \acrshort{io} operations, communication volume, and size for both construction and query stages.

			See \cref{table:protocols} for the snapshot for particular distribution (CA employees).
			\cref{figure:protocols-ios,figure:protocols-size,figure:protocols-vol} shows all values we tracked for all protocols and distributions.
			Values for \acrshort{ore} based protocols are averaged.
			Being ``cold'' in our simulations means executing the first query and being ``warm'' means the first query has been previously executed.
			This difference makes sense only for POPE as its first query incurs disproportionately large overhead by design.

			Note that all \acrshort{ore} based protocols behave the same except when ciphertext size matters.
			Thus, since BCLO, CLWW and FH-OPE have the same ciphertext size, they create {\BPlus} trees with the same page capacity and have the same number of \acrshortpl{io} for different operations.
			Lewi-Wu and CLOZ schemes have relatively large ciphertexts and thus induce larger traffic (see \cref{figure:protocols-size:c}) and smaller {\BPlus} tree branching factor resulting in greater number of \acrshort{io} requests (see \cref{figure:protocols-ios:q}).
			Kerschbaum protocol requires high number of \acrshort{io} requests during construction since it needs to insert an element into the arbitrary place in an array and rotate the data structure on a disk.

			POPE suffers huge penalty on the first query (see \cref{figure:protocols-ios:q,figure:protocols-vol:q,figure:protocols-size:q}) since it reads and sends all blocks to the client for sorting.
			POPE performance improves as more queries are executed.

			\input{figures/fig-protocols-other}

			Logarithmic-BRC does not support interactive insertions and thus its construction stage is not benchmarked.
			Otherwise it is the most performant of all non-\acrshort{ore} protocols.
			Note, however, that its performance depends on the result size, not data size.

			As expected, \acrshort{oram} performs worse than the \acrshort{ore}-based protocols, but its performance is in-line with the non-\acrshort{ore} protocols.
			It may seem that \acrshort{oram} does especially bad in construction communication (\cref{figure:protocols-vol:q,figure:protocols-size:q}), but it is only because POPE has a shortcut in construction.
			This ``debt'' is being payed off during queries (\cref{figure:protocols-size:q}).

			Note that the values do not vary a lot among different data distributions except for \acrshort{io} requests.
			\acrshort{io} performance depends on the result size for queries, and is therefore more sensitive to data distribution.

			Also note that using an \acrshort{ore} scheme with relatively small ciphertext in {\BPlus} tree does not add any substantial \acrshort{io} overhead (see ``No encryption'').


			On \cref{figure:protocols-query-sizes} it is clear that query performance does not depend substantially on the query size, except for Logarithmic-BRC, for which the relation is linear.
			Note that Logarithmic-BRC with optimally configured \texttt{pack} extension shows almost no growth.
			This is because for large ranges \acrshort{brc} will return the higher nodes (keywords matching many documents), which are optimally packed in \acrshort{io} pages.
			As query range doubles, higher nodes are involved increasing the chance that requested keywords have their documents packed.


			\cref{figure:protocols-data-percent-vol,figure:protocols-data-percent-ios} show \cref{table:protocols} asymptotic values.
			The simulation was run for uniform dataset of \num{247000} records (hundred percent), \num{1000} queries, \SI{0.5}{\percent} query range and \num{128} blocks cache size.
			Kerschbaum construction \acrshortpl{io} and cold POPE query values grow linearly with inputs, while the other protocols grow logarithmically, square-logarithmically, or do not grow.

			\cref{figure:cold-vs-warm} shows how the performance of protocols fluctuates as queries are processed.
			Note that POPE and Logarithmic-BRC fluctuate the most (which is, in general, undesirable), and POPE is the only protocol where cold versus warm makes a difference.
