
\chapter{Proposal}
\thispagestyle{myheadings}

	\section{Introduction and Background}

		As the organizations struggle with demands for storage and processing of their data, they increasingly turn to third parties for outsourcing capabilities.
		A number of companies including Amazon (AWS), Microsoft (Azure) and Google (GCP) offer outsourced database solutions to individuals and other businesses.
		This model is lucrative because not only the clients pay exactly for what they use in terms of pure computational resources, but also the cloud takes care of the entire deployment process, including availability, scalability, replication and, most importantly, security.
		Cloud business model is to provide resources on-demand --- from bare-bones \acrshort{vm} to database-as-a-service products.

		While the cloud providers typically have strict customer data privacy policies and even offer server-side encryption-at-rest services, the clients still have to trust the provider with their plaintext data.
		Server-side encryption-at-rest by definition requires the provider to know the encryption key to manipulate the data, even if the key is ephemeral and is not stored in the cloud permanently.
		Moreover, cloud provider in general, and customer's \acrshort{vm} in particular, may be vulnerable to external attacks --- from snapshot-level attacks, in which the adversary has a copy of the \acrshort{vm} memory, to more devastating persistent attacks, in which the adversary continuously monitors the \acrshort{vm} processes.

		Protecting the private information beyond cloud provider guarantees typically requires encrypting it in a way that preserves the ability to process it.
		A line of research targets securing outsourced database systems, but often achieves protection at a cost of efficiency that is too high for a solution to be viable for practical applications.
		In this prospectus, I will cover the constructions that are used to answer different types of database queries in the outsourced model while providing both provable security and practical efficiency guarantees.

		\subsection{Model}\label{section:proposal:intro:model}

			In this work, I consider \emph{an outsourced database system} model, adapted from \cite{generic-attacks-kellaris} and \cite{epsolute}.

			\subsubsection{Outsourced database model}

				Similar to~\cite{epsolute}, a database is abstracted as a collection of \dataSize{} records \record{}, each with a unique identifier \recordID{}, associated with search keys \searchKey{}: \databaseDef{}.
				All records are assumed to have an identical fixed bit-length, and the search keys are elements of some domain \searchKeyDomain{}.
				A query is modeled as a predicate $\query \in \querySet: \searchKeyDomain \to \bin$.
				Evaluating a query \query{} on a database \database{} results in $\query( \database ) = \{ \record_i : \query( \searchKey_i ) = 1 \}$, all records whose search keys satisfy \query{}.

				Formally, an outsourced database system consists of two protocols between a stateful user \user{}, who owns the data, and an untrusted stateful server \server{}, to whom these data are outsourced.
				In setup protocol \protocolSetup{}, \user{} receives as input a database \databaseDef{} and \server{} may optionally output a data structure \serverDS{}.
				In query protocol \protocolQuery{}, \user{} receives a query $\query \in \querySet$, \server{} receives \serverDS{} produced in the setup protocol, and \user{} outputs the result of the query $\query( \database )$.
				Both parties may update their internal states.
				We call a system \emph{correct} if it holds with overwhelming probability over the randomness of the above runs that running \protocolSetup{} and  \protocolQuery{} on the corresponding inputs yields the correct result $\{ \record_i : \query( \searchKey_i ) = 1 \}$.

			\subsubsection{Security model}

				I define two types of adversaries --- a \emph{snapshot} and a \emph{persistent} adversaries.

				A snapshot adversary, as the name suggests, can see a ``snapshot'' of server's data at multiple points in time.
				One can think of such attack as if someone steals a hard drive or accesses a backup.
				Formally, \adversary{} knows \server{} state at all stages of the protocol.

				A persistent adversary is stronger in that she monitors the server continuously.
				Therefore, she can see what snapshot adversary can plus the network traffic and the access pattern.
				Such adversary can be thought of as a malicious software (virus) that runs as a background process with wide permissions.
				Formally, on top of \server{} state, \adversary{} knows the size and content of \server{} communication and the sequence of accesses \server{} makes to its internal state at all stages of the protocol.

				Intuitively, one can think that encrypting records should protect the data.
				Depending on the way the records are encrypted (i.e., whether the semantic or property-preserving encryption is used), this approach can mitigate the snapshot adversary.
				Persistent adversary, however, can observe the communications size even if the traffic itself is encrypted, and can see the access pattern even if the records are protected.
				It has been shown that the knowledge of access pattern~\cite{multidimensional-range-queries, inference-attack-islam-14, leakage-abuse-attacks-cash-15, inference-attacks-naveed-15, generic-attacks-kellaris, attacks-tao-of-inference, grubbs-attacks, access-pattern-disclosure, attacks-improved-reconstruction} or communication volume~\cite{generic-attacks-kellaris, state-of-uniform, attacks-improved-reconstruction, pump-volume-attacks, volume-range-attacks} alone can enable a series of reconstruction attacks.
				Also note that both adversaries are \emph{honest-but-curios} --- they only observe and never interfere.
				Denial-of-service attacks and integrity protection are out of scope of this work.

			\subsubsection{Query types}

				The type of query \query{} is deliberately left abstract.
				The outsourced database system assumes that a query contains a way (a predicate) to select only the records whose search keys satisfy it.
				In this work I consider these types of queries.

				\paragraph*{A point query.}
					This query selects records whose key is equal to a certain value.
					The domain of the point value does not have to be ordered; it can be categorical, like color names.
					The relevant SQL query can be

					\texttt{SELECT * FROM t1 WHERE zip = '02215'}.

				\paragraph*{A range query.}
					This query selects records whose key lies between two values from an ordered domain.
					The relevant SQL query can be

					\texttt{SELECT * FROM t1 WHERE age BETWEEN 18 and 65}.

				\paragraph*{A \acrshort{knn} query.}
					\acrlong{knn} query selects $k$ records whose keys are ``closest'' to a certain value.
					This query type requires a definition of distance metric over the domain of search keys, for example, simple Euclidean distance.
					The relevant SQL query can be

					\texttt{SELECT * FROM t1 ORDER BY location <-> '(29.9691,-95.6972)' LIMIT 5}. % chktex 36

		\subsection{Proposal}

			I propose to structure the thesis around the problem of answering the aforementioned three query types securely in the presence of snapshot or persistent adversaries.
			The thesis will include a rich background on proposed secure query processing solutions and attacks against these solutions.
			I will explain the components that are needed to construct the solutions, including symmetric encryption, property-preserving encryption, \acrlong{oram} and Differential Privacy.

	\section{Range queries in a snapshot model}

		\subsection{Problem}

			There are a plenty of works offering range query solutions in a snapshot adversary model.
			Some authors propose a new \acrfull{ore} scheme to be used inside an existing range query index, see \cite{bclo-ope,clww-ore,lewi-wu-ore,cloz-ore,fh-ope}.
			Others suggest full client-server protocols with different security guarantees, see \cite{florian-protocol,pope,practical-ore}.

			Instead of adding another solution to the mix, we developed a robust evaluation framework to compare and audit different \acrshort{ore} schemes and range query protocols \cite{ore-benchmark-17}.
			We have noticed that all proposed solutions offer their own formal protocol, security definition (which they obliviously satisfy), and even performance metrics.
			Moreover, only a few of these algorithms have ready-to-use open-sourced code.
			More often, the implementation is a prototype (or does not even exist), rendering experiments non-reproducible.

		\subsection{Solution}

			Our work addresses these shortcomings.
			We proposed a common framework where all analyzed solutions follow the same formal protocol, a variant of outsourced database from \cref{section:proposal:intro:model}.
			The schemes and protocols are also tested against the same security definition, a variant of simulation-based security game where simulator has a leakage function that is different for each solution.
			Lastly, all protocols are implemented in the same language and runtime, and are using the same cryptographic primitive implementations.

			We have paid extra attention to how we quantify the performance.
			Published works typically claim that they have implemented the algorithm in some language and ran it on a server many times measuring the wall-clock time.
			Such metric is deeply flawed since it only measures just that --- the wall-clock time it took for a particular machine to execute a particular code that references particular implementations of primitives and makes (or even does not make) \acrshort{io} requests to particular hardware.
			What we offer is a metric that drops all these ``particulars'' (i.e., dependencies) from the protocol execution.
			On top of having all solutions implemented in the same language and using same primitives, instead of measuring the time we count the number fo times an \acrshort{ore} scheme makes use of a primitive and a protocol makes an \acrshort{io} request.
			This metric is much more demonstrative: one can always get a wall-clock time estimate given these counts and the specs of the hardware.
			Moreover, we can analyze these counts theoretically from the pseudocode and then verify them practically after running the code.

		\subsection{Results}

			In our work we apply the framework to ten range query solutions.
			Five protocols are built with an \acrfull{ore} scheme coupled with a \BPlus{} tree.
			In \protocolSetup{}, \client{} encrypts all search keys with the \acrshort{ore} scheme, constructs a \BPlus{} tree from the ciphertexts and uploads to \server{}.
			In \protocolQuery{}, \client{} sends encrypted query endpoints and \server{} follows standard \BPlus{} traversal.
			Such protocol leaks the total order of the records plus the leakage of the underlying \acrshort{ore} scheme.

			We also analyzed dedicated range query protocols from \cite{florian-protocol,pope,practical-range-search} and two more baselines.
			Baselines are chosen at the extremes of performance / security spectrum --- a plaintext \BPlus{} tree and a \BPlus{} tree in \acrshort{oram}.
			Intuitively, all solutions should lie between the baselines in both performance and security, but we show that at least performance-wise it is not the case (see one of the plots in \cref{figure:ore}).

			Please see \cref{table:ore,table:range} in \cref{appendix:ore-results} for the analytical results for each solution, and \cite{ore-benchmark-17} for experimental results.

			\include{figures/fig-ore}

	\section{Range and point queries in a persistent model}\label{section:range-queries-persistent}

		\subsection{Motivation and Background}

			A persistent adversary is capable of observing not only the data at any point in time (like the snapshot attacker), but also all processes and communication on the server, including the network messages, their size and the access pattern to the storage.
			A series of attacks starting with a seminal work of \textcite{generic-attacks-kellaris} showed that the query result size~\cite{generic-attacks-kellaris, state-of-uniform, attacks-improved-reconstruction, pump-volume-attacks, volume-range-attacks} and access pattern~\cite{multidimensional-range-queries, inference-attack-islam-14, leakage-abuse-attacks-cash-15, inference-attacks-naveed-15, generic-attacks-kellaris, attacks-tao-of-inference, grubbs-attacks, access-pattern-disclosure, attacks-improved-reconstruction} alone could enable reconstruction attacks.
			The attacks against access pattern typically exploit the fact that some records are accessed more often than others and in the same query as others.
			The adversary maps this knowledge to some public auxiliary dataset and queryset and guesses the values correctly with a non-negligible probability.
			Attacks on communication volume are more elaborate and use the fact that there are a well-defined number of distinct interval queries over the domain.
			\textcite{generic-attacks-kellaris}, for example, construct a polynomial with the observed number of queries that return a different number of records, and solve it deriving the exact reconstruction.

			A generic way to protect the access pattern is the \acrfull{oram}, an interactive client-server protocol that conceals the access pattern from the observing adversary by making at least $\bigO{\log n}$ extra requests.
			A na\"{\i}ve solution is to simply proxy all requests through the \acrshort{oram} protocol, but it is generally inefficient and not trivially parallelizable.

			Protecting against communication volume leakage usually involves returning a number of extra fake records and letting the client filter them out locally.
			Where approaches differ is in the number of these fake records.
			A na\"{\i}ve way of adding a constant amount of noise or even sampling noise uniformly is insecure since such noise can be filtered out by the adversary either immediately (constant noise), or after observing a certain number of queries (uniform noise).
			Another dimension to the problem is how much noise to add to have a provable guarantee and yet add the smallest amount of noise possible.

			\subsubsection{Differential Privacy}

				The most effective approach is sampling noise using \acrfull{dp}.
				\acrshort{dp} is a guarantee on a query algorithm that takes a database and returns some result.
				The guarantee states that for two neighboring databases (that differ in one record), the probability that the adversary will understand by looking at the output, which of the two databases was used as an input, is bounded.
				More formally, the \acrshort{dp} is defined in \cref{definition:dp}.

				\begin{definition}[Differential Privacy, adapted from~\cite{our-data-ourselves, differential-privacy-original}]\label{definition:dp}
					A randomized algorithm \algo{A} is $(\epsilon, \delta)$-differentially private if for all $\database_1 \sim \database_2 \in \searchKeyDomain^\dataSize$, and for all subsets $\mathcal{O}$ of the output space of \algo{A},
					\[
						\probability{ \algo{A}{ \database_1 } \in \mathcal{O} } \leq \exp(\epsilon) \cdot \probability{ \algo{A}{ \database_2 } \in \mathcal{O} } + \delta \; .
					\]
				\end{definition}

				One way to interpret this definition is the following.
				Probabilities are taken over the coins of algorithm \algo{A}, which answers a query based on a dataset.
				A natural instantiation of \algo{A} is a view of a distinguishing adversary \adversary{}, who tries to guess which of the two datasets was used.
				The expression in \cref{definition:dp} then bounds the advantage of \adversary{} with $\epsilon$ and $\delta$ parameters.
				Note that $\exp( x ) \approx 1 + x + \frac{x^2}{2!}$ and for sufficiently small $x$ the last term is negligible.
				If we put $\epsilon + 1$ in place of $\exp( \epsilon )$, it becomes clear that $\epsilon$ is the exact value by which two probabilities are allowed to differ.
				For $\epsilon = 0$, they have to be equal, for $\epsilon = 0.01$, probabilities may differ by \SI{1}{\percent}.
				Therefore, $\epsilon$ is called \emph{a privacy budget} of a \acrshort{dp} system.
				$\delta$ term is additive and therefore must be small by itself.
				This term is essentially a probability that the entire system fails.
				For example, if \algo{A} is a randomized algorithm that fails with a certain chance, this probability will be $\delta$.
				For instance, a PathORAM \cite{path-oram} algorithm can have a stash overflow with a bounded probability \cite[Theorem 1]{path-oram} and it will cause the entire algorithm to fail.
				If PathORAM is used in a \acrshort{dp} system then this probability, however small, bounded and negligible, will have to be accounted for in $\delta$.

				Note that \cref{definition:dp} describes a property of \algo{A} and not a construction method.
				To construct \algo{A}, the seminal \cite{differential-privacy-original} offers an algorithm called \acrfull{lpa}.
				The idea is to tune the noise sampled from Laplacian distribution to the \emph{sensitivity} of a query, defined as the change of output with respect to change in input.
				For example, if a change in one record of the dataset causes a change in the output value of at most one (e.g., a count query), then the sensitivity is 1.
				\cite{differential-privacy-original} proves that if one adds $\algo{Laplace}{0, \frac{\mathsf{sensitivity}}{\epsilon}}$ to the real result of a query, the resulting mechanism is $\epsilon$-\acrshort{dp}.

				Lastly, instead of generating and adding noise each query, it is possible to generate noisy values once, embed them into the data and release the sanitized data without compromising privacy guarantees.
				The intuition is that once the noise is embedded in the dataset, the adversary can run a regular query over it and the entire query will still be \acrshort{dp}.
				Such methods are collectively called \emph{sanitization}, and there are known bounds for point and range queries, for pure ($\delta = 0$) and approximate ($\delta > 0$) \acrshort{dp} \cite{bounds-on-sample-complexity,private-learning-and-sanitization,non-interactive-database-privacy,dp-under-observation,dp-release,privately-learning-thresholds}.

		\subsection{Security definition}

			In this work we aim for the most practical definition of security, which needs to capture both access pattern and communication volume protection and yet be feasible enough so that an efficient system exists that can satisfy it.
			In \epsolute{} \cite{epsolute} we propose a definition of computationally \acrshort{dp} outsourced database.

			\begin{definition}[\acrfull{cdpodb} from Definition 3.1 in \cite{epsolute}]\label{definition:cdpodb}
				We say that an outsourced database system \protocol{} is $(\epsilon, \delta)$-computationally differentially private (a.k.a.\acrshort{cdpodb}) if for every polynomial time distinguishing adversary \adversary{}, for every pair of neighboring databases $\database \sim \database^\prime$, and for every query sequence $\fromNtoM{\query}{1}{m} \in \querySet^m$ where $m = \mathsf{poly}(\lambda)$,

				\begin{multline*}
					\probability{\adversary \left( 1^\lambda, \view{\protocol, \server}{\database, \fromNtoM{\query}{1}{m}} \right) = 1 } \leq \\
					\exp{\epsilon} \cdot \probability{\adversary \left( 1^\lambda, \view{\protocol ,\server}{\database^\prime, \fromNtoM{\query}{1}{m}} \right) = 1} + \delta + \negl \; ,
				\end{multline*}
				the probability is over the randomness of the distinguishing adversary \adversary{} and the protocol \protocol{}.
			\end{definition}

			First thing to note in this definition is that unlike in prior works where only a part of \adversary{}'s view is \acrshort{dp}-protected (e.g., only access pattern in \cite{differential-obliviousness,differential-obliviousness-followup}), here the entire view of the adversary is protected.
			That is, if \emph{anything} that is visible during the execution of the protocols to a persistent adversary can be used to distinguish the neighboring datasets, the adversary wins and the system fails to satisfy the definition.
			Subsequently, it implies protection against both access pattern and communication volume, since they are both a part of the view and if the adversary sees either of them, she can distinguish.

			Also note that the \acrshort{cdpodb} system is \acrshort{dp}, but not necessarily semantically secure.
			A semantically secure database would have had probabilities almost equal (or, in \cref{definition:cdpodb}, $\epsilon = 0$).
			The trade-off has been made to allow construction of an efficient system.
			While a na\"{\i}ve solution that satisfies semantically secure definition would return entire dataset every query, constructing a practical instantiation is hard, is not necessarily possible, and remains an open problem.

			The negligible term $\negl$ at the end was added to account for the computational (as opposed to the information-theoretical) nature of the definition.
			In the information-theoretical system the security is guaranteed by the clear mathematical proof that the adversary can do nothing better than brute-force the system (e.g., iterating over one-time-pad keys).
			A computational security definition relies on the fact that the adversary simply does not have enough resources to break a system, which may or may not hold true in the future.
			For example, the problems of finding a discrete logarithm and factorization are only assumed to be hard, as are standardized block ciphers, such as AES \cite{aes-nist}.
			Therefore, if we want to allow a system to use these cryptographic blocks for security, we must include the negligible term in the definition.

			Finally, note the query sequence $\fromNtoM{\query}{1}{m} \in \querySet$ is fixed.
			The definition is non-adaptive meaning that the user \user{} must not choose the next query based on the result of the previous one.
			In \cite[Section 3.1.1]{epsolute} we prove by example why this limitation is inherent and no efficient system can be built that would allow adaptive queries.

		\subsection{\epsolute{}}

			In \epsolute{} \cite{epsolute}, we develop a method of answering point and range queries that satisfies \cref{definition:cdpodb}.
			At the heart of the construction is the use of \acrshort{oram} to hide the access pattern and \acrshort{dp} to add extra fake records to the result to hide communication volume.

			\acrshort{oram} component is straightforward --- communication between \user{} and \server{} is routed through the \acrshort{oram} protocol.
			This approach, however, substantially increases the overhead, which I will address in \cref{section:range-queries-persistent:parallel-epsolute}.

			To optimally add noise to the true result we make use of sanitizers for point and range query types.
			For point queries, we construct a histogram from the domain values.
			We put the number of records for the domain value plus the noise sampled from the Laplacian distribution into each bin.

			\input{figures/fig-sanitizer}

			For the range queries we use a hierarchical sanitizer \cite{hierarchical-methods-for-dp}, see example in \cref{figure:sanitizer}.
			We first split the continuous domain into bins.
			Then we build a \fanout{}-ary tree over domain bins and put the number of records plus noise into each node.
			The leaves get values the same way as in histogram, and intermediate node value is a sum of counts of all records in all children bins plus a single noise sample.
			Compared to a plain histogram, this construction has the benefit that if the range is wide we can answer the query using only the intermediate node and not all leaf nodes.
			Since each bin is now associated with $\ceil{\log_\fanout B}$ nodes, where $B$ is the number of bins, we amplify our noise respectively.

			Note that the Laplacian distribution is symmetrical and unbounded, so if we sample from a zero-mean distribution some of the samples will be negative.
			Since we do not allow negative noise and since na\"{\i}vely truncating the distribution will break \acrshort{dp} guarantees, we need to shift the mean of the distribution.
			Doing so will only increase the noise thereby maintaining the guarantees.
			We have analytically derived the smallest mean of the distribution to ensure that the samples are non-negative for the entire histogram or tree with a set probability $\delta$.
			These values are
			\[
				\mu_{\mathsf{point}} = \ceil{ -\frac{ \ln \left( 2 - 2 \sqrt[\domainSize]{1 - \delta} \right) }{ \epsilon } } \quad \text{and} \quad \mu_{\mathsf{range}} = \ceil{ -\frac{ \ln{ (2 - 2 \sqrt[\mathsf{nodes}]{ 1 - \delta } ) } \cdot \log_{\fanout} \domainSize }{\epsilon} }
			\]
			for domain size \domainSize{} and the number of nodes in a tree $\mathsf{nodes}$.

			With these prerequisites we construct the actual setup and query protocols.
			See visualization of \protocolQuery{} in \cref{figure:epsolute}.
			\begin{itemize}
				\item
					Setup protocol \protocolSetup{}
					\begin{enumerate}
						\item
							On input a dataset \database{}, \user{} creates and keeps locally an inverted index over the records mapping the search keys \searchKey{} to record IDs \recordID{}.
						\item
							\user{} and \server{} engage into the \acrshort{oram} protocol, where \user{} is a client.
							\user{} stores all records by their IDs.
						\item
							\user{} constructs a sanitized structure \serverDS{}, a \acrshort{dp}-histogram for point queries or a \acrshort{dp}-tree for range queries, over the domain of the dataset and posts it to \server{}.
					\end{enumerate}
				\item
					Query protocol \protocolQuery{}
					\begin{enumerate}
						\item
							On input a query \query{}, \user{} looks up record IDs in its local index.
						\item
							\user{} requests \serverDS{} from \server{} and uses it to calculate the total number of requests $c$ (the number of true records for the query plus noise).
						\item
							\user{} and \server{} engage into the \acrshort{oram} protocol, where \user{} is a client.
							\user{} loads $c$ records where these requests include all true records and the rest are random and non-repeating.
						\item
							\user{} prunes the fake records and returns the true ones.
					\end{enumerate}
			\end{itemize}

			\input{figures/fig-epsolute}

			This method, to which I will refer to as \emph{a single-threaded \epsolute{}}, is a \acrlong{cdpodb} as defined in \cref{definition:cdpodb}, see proof in \cite[Section 4.2]{epsolute}.

		\subsection{Parallel \epsolute{}}\label{section:range-queries-persistent:parallel-epsolute}

			While the single-threaded \epsolute{} is an efficient \acrshort{cdpodb} in the sense that it returns only a fraction of total records per query, it is still slow in practice because of the $\bigO{\log \dataSize \log \domainSize}$ overhead due to \acrshort{oram} and \acrshort{dp}-sanitizer.
			To bring the construction closer to real-world demands in performance we devise a parallel solution.

			\subsubsection{A choice of separate vs shared sanitized dataset}

				A natural approach is to split the dataset \database{} into \oramsNumber{} partitions and run parallel \acrshort{oram} protocols against a distributed \server{}.
				The partitioning part is not hard --- we split records by the hash of their unique ID and we construct smaller (and thus logarithmically faster) \acrshortpl{oram} over the partitions along with \oramsNumber{} inverted indices on \user{}.
				However, we need to decide how we sample \acrshort{dp} noise in this setting.
				The two approaches are generating a separate \serverDS{} per partition or using a shared \serverDS{}.

				When generating a separate \acrshort{dp}-sanitized dataset \serverDS{} per partition there are two competing effects on performance.
				On the one hand, each thread on average returns a \nicefrac{1}{m} fraction of the result from an \acrshort{oram} with overhead $\log \frac{n}{m}$.
				On the other hand, each thread now adds independent noise, which results in \oramsNumber{} amplification of noise.
				Moreover, due to the \acrshort{dp} composition theorem \cite{privacy-integrated-queries,differential-privacy-original,our-data-ourselves} for disjoint datasets, the privacy budget of the system is the privacy budget of the least private component.
				Since we cannot assume that the distribution of resulting records in all queries is always uniform, we bound a worst-case scenario of a single \acrshort{oram} having most of the result records.
				In \cite[Section 5.1]{epsolute} we have found that the noise is amplified by an extra $\left( 1 + \sqrt{ \frac{-3 m \log \delta}{k_0} } \right)$ factor, where $k_0$ is the number of true records for a query.

				When generating a single shared \serverDS{} for all \oramsNumber{} partitions, we need to ensure that the total number of records returned by each thread is the same.
				We reuse the amplification factor from previous approach and set new $\tilde{k}_0 = k_0 + \frac{\log^{1.5} N}{\epsilon}$ for range queries and $\tilde{k}_0 = k_0 + \frac{\log N}{\epsilon}$ for point queries due to the use of \acrshort{dp} sanitizers.
				The total generated noise is now larger but it is now split among \oramsNumber{} threads and it grows slower than linear in \oramsNumber{}.

				Comparing these two methods we conclude that in most cases the shared \serverDS{} is faster (i.e., results in fewer total fetched records), especially for an increasing parallelization factor.
				First, the former method is not guaranteed to have a uniform load among threads.
				In fact, while on average the amount of work per thread may be smaller, there may be a single disproportionally overloaded thread, which would cause the entire system to slow down.
				Second, while the number of true records per thread will decrease linearly for the former method, the noise factor will stay constant and will at larger \oramsNumber{} dominate the amount of work precluding further scalability.
				The latter method is more scalable in this regard since the amount of work decreases linearly while the amount of noise increases only logarithmically with the number of threads.

			\subsubsection{The construction}

				With this analysis I present an upgraded construction, \emph{a parallel \epsolute{}}, see \cref{figure:parallel-epsolute}.
				The core protocol is similar to the single-threaded version except some of the operations are distributed and executed in parallel.
				\begin{itemize}
					\item
						Setup protocol \protocolSetup{}
						\begin{enumerate}
							\item
								On input a dataset \database{}, \user{} partitions it into \oramsNumber{} segments \fromNtoM{\database}{1}{\oramsNumber} by a hash of record IDs \recordID{}.
								\user{} then creates and keeps locally \oramsNumber{} inverted indices over the records mapping the search keys \searchKey{} to record IDs \recordID{} in a respective partition.
							\item
								\user{} and distributed \server{} engage into \oramsNumber{} \acrshort{oram} protocols, where \user{} is a client.
								\user{} stores all records by their IDs in respective \server{} partitions.
							\item
								\user{} constructs a sanitized structure \serverDS{} (or \oramsNumber{} such structures depending on the choice of method) over the domain of the dataset and posts it to \server{}.
						\end{enumerate}
					\item
						Query protocol \protocolQuery{}
						\begin{enumerate}
							\item
								On input a query \query{}, \user{} looks up record IDs in its local indices.
							\item
								\user{} requests \serverDS{} (one or multiple) from \server{} and uses it to calculate the total number of requests $c$.
								Depending on the choice of method, \user{} prepares a sequence of requests to \server{}.
							\item
								\user{} and \server{} engage into \oramsNumber{} \acrshort{oram} protocols, where \user{} is a client.
								\user{} loads a total of $c$ records where these requests include all true records and the rest are random and non-repeating.
							\item
								\user{} waits for the last thread to finish, prunes the fake records and returns the true ones.
						\end{enumerate}
				\end{itemize}

				As a purely practical optimization, instead of making a single client \acrshort{vm} engage into \oramsNumber{} (up to 128 in the experiments) connections and heavy cryptographic threads, we logically split \user{} into a principal \acrshort{vm}, which handles main logic, and a set of helper \acrshortpl{vm} that only engage in a number of \acrshort{oram} protocols.

				\include{figures/fig-parallel-epsolute}

		\subsection{Experimental evaluation}

			To empirically verify the efficiency and practicality of our solution, we have implemented the construction in C++ \cite{github-epsolute} and have run an extensive set of experiments.
			We have designed the experiments to
			\begin{enumerate*}[label=(\alph*)] % chktex 36
				\item compare our system to competing proposed systems,
				\item measure the storage overhead,
				\item tune the parameters of the system and observe the effect on performance,
				\item see how the system scales,
				\item understand the quantitative impact of our optimizations, and
				\item measure the impact of supporting multiple attributes.
			\end{enumerate*}

			For the default setting we ran range queries in the parallel \epsolute{} using shared \serverDS{} method.
			Client \acrshort{vm} managed $\oramsNumber = 64$ threads, which are split among 8 lightweight \acrshort{oram} \acrshortpl{vm}.
			Client \user{} and server \server{} are located in geographically distributed regions, with the ping time between the regions \SI{12}{\milli\second} and the effective bandwidth \SI{150}{\mega\byte\per\second}.
			In this section I will focus on comparing \epsolute{} to relevant systems and on \epsolute{}'s scalability.
			I refer to the full work for the rest of the experimental findings \cite[Section 6]{epsolute}.

			\subsubsection{Against relevant solutions}

				In \cite{epsolute}, we compared \epsolute{}
				\begin{enumerate*}[label=(\alph*)] % chktex 36
					\item to conventional \acrshort{sql} \acrshortpl{rdbms} (PostgreSQL and MySQL),
					\item to a linear scan approach, and
					\item to Shrinkwrap \cite{shrinkwrap}.
				\end{enumerate*}

				\acrshortpl{rdbms} are highly optimized for range queries --- the records indexed by search keys are typically stored continuously in-order and the database streams back these blocks very efficiently.
				As a baseline approach, \acrshortpl{rdbms} were configured for maximum performance and minimum security.

				Linear scan is a strawman approach, which downloads the entire encrypted dataset every query, decrypts it and then runs the query locally.
				This is the opposite baseline of maximum security and poorest performance.
				Such approach is not entirely theoretical: some commercial \acrshortpl{rdbms} exhibit linear scan behavior when configured for maximum security, for example MS-SQL Always Encrypted with Randomized Encryption \cite{mssql-always-enc} and Oracle Column Transparent Data Encryption \cite{oracle-tde}.

				Shrinkwrap \cite{shrinkwrap} is a construction that executes federated \acrshort{sql} queries securely, albeit inefficiently.
				To hide communication volume it fully pads the intermediate results of the sub-queries (although it ``shrinks'' the output before passing it to the next stage).
				To hide the access pattern, the algorithm does a linear scan over the entire input.
				Moreover, to process the encrypted data (e.g., evaluate a predicate), the whole program is compiled into garbled circuits \cite{yao-circuits,emp-toolkit}.

				\input{figures/fig-mechanisms}

				We conclude that \epsolute{} is efficient --- while answering a query in \SI{840}{\milli\second}, it is only 8 to 4 times slower than a typical \acrlong{rdbms}, 18 times faster than the scan, and three orders of magnitude faster than the Shrinkwrap, see \cref{figure:mechanisms}.

			\subsubsection{Scalability}

				To measure scalability we have run parallel \epsolute{} with shared and separate \acrshort{dp}-sanitized datasets \serverDS{} for a varying number of threads \oramsNumber{}.
				For a truly scalable system we would observe a drop in overhead roughly proportional to the increase in parallelization factor \oramsNumber{}.
				We confirm experimentally that \epsolute{} is scalable when a shared \serverDS{} is used as a method of noise generation, see \cref{figure:scalability}.
				The noise dominates the performance of separate \serverDS{} method for higher number of threads, while separate \serverDS{} method continues to scale.

				\input{figures/fig-scalability}

	\section{\acrshort{knn} queries in a snapshot model}

		Nearest neighbor search is a type of optimization problem that, given a set of objects and a distance metric, requires to find the object that is closest to a given object according to the distance metric.
		A \acrfull{knn} search is a subtype of a general nearest neighbor problem where $k$ closest objects are requested.
		Applications that use \acrshort{knn} search only need to define the objects and the metric.
		For example, a street map application would define the 2D coordinates of the buildings as objects and Euclidean distance as a metric, and the query could be ``give 5 restaurant closest to the current user position''.
		A document search application would define the keyword vector for a document as an object and an inner product distance as a metric, and the query could be ``give 3 documents most similar to the given text'' (similar applications may search images, videos and sounds).

		To run a \acrshort{knn} query securely in an outsourced database model, I propose to use an approach similar to \acrshort{ore} for range queries.
		While to run a range query one needs to be able to \emph{compare} the ciphertexts (exactly what \acrshort{ore} does), to run a \acrshort{knn} query one needs to know \emph{a distance comparison} between pairs of ciphertexts.
		That is, one needs to maintain (or reveal) an order of distances of all pairs of encrypted objects.
		For example, if $x$ was further from $y$ than $z$ was, then the encryption of $x$ needs to be further from the encryption of $y$ than the encryption of $z$ is.

		Although such a \acrfull{dcpe} scheme would allow to run the query with an absolute accuracy, the construction would suffer from the same security issues that the \acrshort{ore} methods did.
		Most of all, while \acrshort{ore}-encrypted dataset reveals the total order, the \acrshort{dcpe}-encrypted values will reveal \emph{the total relative position} of all elements.
		The exact distances will be hidden (subject to the \acrshort{dcpe} scheme's own leakage), but the relative position is a substantial leakage that may lead to reconstruction attacks.
		To mitigate the leakage we may use a form of \emph{an approximate} \acrshort{dcpe}, which ideally would add controlled noise or inaccuracy to the relative distances.

		\subsection{\acrlong{dcpe}}

			A candidate approximate \acrshort{dcpe} scheme has been proposed by \textcite{dcpe}.
			The scheme provides the following guarantee on its ciphertexts
			\[
				\forall x, y, z \in \mathbb{X} : \algo{Dist}{x, y} < \algo{Dist}{x, z} - \beta \implies \algo{Dist}{f(x), f(y)} < \algo{Dist}{f(x), f(z)}
			\]
			where $\mathbb{X} \subseteq \mathbb{R}^d$ is the set of $d$-dimensional vectors of real numbers, \algo{Dist} is the inner product distance over elements in $\mathbb{X}$, and $\beta$ is the approximation factor.
			Parameter $\beta$ partially defines the security of the encrypted set --- the larger $\beta$, the fewer distance comparisons are preserved, the less accurate the search and the reconstruction attacks would be.
			\textcite{dcpe} prove protection against membership inference attacks \cite{memebership-inference-attacks-knn} (whether individual is in the database or not), and against approximate frequency-finding attacks (how many times the element appears in the set, see \cite{leakage-abuse-grubs-2017} for \acrshort{ore} frequency attacks).
			As for the choice of $\beta$, \cite{dcpe} proves that $\beta \approx \sqrt{\max N}$ would hide about half of the inputs bits, for $\max N$ being the maximum length of a vector in the dataset.

			The scheme works by amplifying the input vector length by a secret factor, then constructing a $d$-dimensional $\beta$-radius hyperball, and finally setting the vector's tip to a uniformly sampled point on that ball.
			The decryption uses the same secret seed and thus constructs the same amplification factor and the same ball, then makes the inverse arithmetic steps to derive the original vector.
			The security of the scheme thus depends on the maximum amount of amplification, the radius of the hyperball $\beta$ and the size of seed for the samplers.
			As the construction operates on real numbers, an open question remains on how to avoid negative side-effects of floating point numbers bit representation.
			I refer to the original paper \cite{dcpe} for the detailed $\beta$-\acrshort{dcpe} construction.

		\subsection{The setup and query protocols}

			With the $\beta$-\acrshort{dcpe} as a component, we can model the protocols similar to \acrshort{ore} ones.
			In the setup protocol \protocolSetup{}, \user{} simply encrypts the entire input, one vector at a time, and sends the encrypted data over to \server{}.
			In the query protocol \protocolQuery{}, \user{} encrypts the query with \acrshort{dcpe}, sends the ciphertext to \server{}, while \server{} runs a standard \acrshort{knn} search against the ciphertext.
			$k$ encrypted vectors are then returned to \user{}, who decrypts them as the last step.
			These protocols run for a single set of secrets including $\beta$.
			To measure the effect of different levels of security on the search accuracy, I propose to repeat the experiments for different values of $\beta$.

			For the choice of the dataset, I suggest using the established information retrieval \acrshort{trec} test collections.
			Such collection consists of set of documents, set of topics (questions) and a corresponding set of relevance judgments (right answers).
			To use the test collection, we need to convert the documents and queries into vectors.\footnote{
				Hamed Zamani has collaborated with us and provided the vectorized data and query sets.
			}
			A benefit of using a \acrshort{trec} dataset is being able to evaluate relevant metrics over the produced results, for example, \acrshort{mrr} \cite{mrr} and \acrshort{dcg} \cite{dcg}.
			We can then track how these metrics, along with the simpler edit distance and set difference over the result, degrade with higher security.

			Lastly, for an actual implementation I suggest using an existing component for the bare \acrshort{knn} search.
			\acrshort{faiss}~\cite{faiss} is a \acrshort{gpu}-enabled library for efficient similarity search and clustering of dense vectors.
			Given that the \acrshort{trec} vectors are $d = 768$ dimensional with a maximum Euclidean length of 11, \acrshort{faiss} seems to be an ideal candidate.
