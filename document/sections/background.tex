\chapter{Background}\label{section:background}
\thispagestyle{myheadings}

	In this section, I will go over the building blocks required to construct the outsourced database systems and their components that I will discuss in the next chapters.
	These prerequisites include the symmetric encryption, \acrshortpl{oram} and PathORAM \cite{path-oram} in particular, \acrlong{dp} and \acrshort{dp} sanitizers, and finally, \acrlongpl{tee}.
	Some of the following sections were paraphrased or taken verbatim from my published work, \cite{ore-benchmark-17,epsolute}.

	\section{Symmetric encryption}

		Symmetric encryption scheme is a tuple of algorithms $\algo{E} = \{ \kgen, \enc, \enc \}$ with the following properties.
		$\algo{E}.\kgen \left( \secparam \right) \to \key$ is a \emph{randomized} algorithm that on a security parameter $\secparam$ returns a key that will be used for both encryption and decryption.
		$\algo{E}.\enc \left( m \right) \to c$ is a \emph{randomized} algorithm that on a plaintext message $m \in \bin^*$ produces its ciphertext $c \in \bin^*$.
		$\algo{E}.\dec \left( c \right) \to m$ is a \emph{deterministic} algorithm that on a ciphertext $c \in \bin^*$ produces its original plaintext message $m \in \bin^*$.

		\subsection{Security}

			The security of the symmetric encryption is typically defined as the indistinguishability under a certain attack.
			The definition is structured around the game between the challenger and the adversary \adversary{}.
			The challenger fixes one of the two ``worlds'', left or right, and the adversary wins the game if she can reliably tell which world it is.

			The weaker security definition, \acrfull{ind-cpa}, intuitively requires that the ciphertext leaks nothing about the plaintext.
			To formalize the requirement, the adversary can give the challenger a set of plaintext pairs to encrypt, and the challenger responds with a set of ciphertext where the left or the right part was encrypted.
			The adversary can then use any (polynomial) algorithm over the ciphertexts and makes a guess of whether the left or the right part was encrypted.
			The claim is, if there is anything that the ciphertext leaks about the plaintext, there exists an adversary which will win.
			The security claim is therefore contrapositive --- the scheme is \acrshort{ind-cpa} secure iff there is no such adversary that wins the game.
			The \acrshort{ind-cpa} definition can be upgraded to allow the adversary to choose the plaintext adaptively (\acrshort{cpa}2), or require the ciphertext be indistinguishable from the random bit-string (\acrshort{cpa}\$).

			\acrshort{ind-cpa} security is not by itslef sufficient since it does not account for a decryption part of the scheme.
			There are known attacks that decrypt the plaintext (i.e., defeat the encryption) if the adversary can trigger the decryption and observe the process or the result, see padding attack \cite{padding-attack} and \acrshort{xml} encryption attack \cite{xml-break-encryption}.

			The stronger definition, \acrfull{ind-cca}, captures the decryption component.
			It extends the \acrshort{ind-cpa} game in that the adversary can now request the challenger to decrypt \emph{any} ciphertext of her choice \emph{excpet} the ones that the chalenger himself encypted for the adversary.
			The adversary still outputs a guess of the two worlds and wins if reliably guesses correctly.
			Note that in this game if the decryption can fail for any reason, or even if \adversary{} can observe any difference in execution for different inputs, the scheme in insecure.
			Therefore, \acrshort{ind-cca} immediately ruls out the aformentioned attacks \cite{padding-attack,xml-break-encryption}.
			Similarly to \acrshort{ind-cpa}, \acrshort{ind-cca} also has the adaptive and indistinguishable\hyp{}from\hyp{}pseudorandom variants \acrshort{cca}2 and \acrshort{cca}\$.

		\subsection{Components}

			Note that for the practical purposes I define the encryption algorithm as randomized --- producing different ciphertext for the same plaintext on every invocation.
			While this is how the symmetric encryption scheme is used in applications, formally, producing the deterministic ciphertext and randomizing it are different operations.

			Internally, the encryption scheme consists of a keyed \acrfull{prp} (also known as a \emph{block cipher}), a \acrfull{prg} that is used to generate a (pseudo)random \acrfull{iv} and a block cipher \emph{mode of operation}.\footnote{% chktex 36
				Here I describe the \emph{block ciphers} family of symmetric encryption algorithms.
				Streaming ciphers are not used this thesis.
			}
			First, the input $m \in \bin^*$ is split into blocks (depending on the underlying block cipher, for example, 128 bits) and the last block is padded if necessary.
			Second, the pseudorandom \acrlong{iv} of size of the block is generated with a \acrshort{prg}.
			Intuitively, this is the part that contributes the  ``randomness'' to the process.\footnote{
				There some modes of operation that do not require the \acrlong{iv}, such as \acrfull{ecb} mode, but these are insecure.
			}
			Finally, the \acrshort{iv} is prepended to the plaintext blocks and the algorithm applies the permutation to one block at a time with the input masked according to a mode of operation.
			The resulting object is a ciphertext that is one block longer than a plaintext due to \acrshort{iv}.
			In practical systems, the ciphertext is then broken up into components, like the ciphertext material itself, the \acrshort{iv}, the version of the key, etc.
			Also note that the encryption scheme key typically has a maximum number of times it can be used for encryption (its \emph{operational lifetime}).

		\subsection{Standardized primitives}

			\acrfull{aes} is a \acrshort{nist}-standardized block cipher, which along with the standardized mode of operation and \acrshort{prg} used to generate the \acrshort{iv} forms the symmetric encryption system.

			\subsubsection{Block cipher: \texorpdfstring{\acrfull{aes}}{Advanced Encryption Standard}}

				Current standard of a block cipher is \acrfull{aes} \cite{aes-nist}.
				It supersedes the \acrfull{des} \cite{des-nist}, which due to its small key is vulnerable to brute force attacks \cite{breaking-des}.


			% In this section I will briefly describe the \acrshort{aes} algorithm, the \acrshort{cbc} and \acrshort{ctr} modes of operation, and the standardized \acrshort{prg} used to generate the \acrshort{iv}.

	\section{\texorpdfstring{\acrlong{oram}}{Oblivious Random Access Machine}}

		\subsection{PathORAM}

	\section{\texorpdfstring{\acrlong{dp}}{Differential Privacy}}

		The most effective approach is sampling noise using \acrfull{dp}.
		\acrshort{dp} is a guarantee on a query algorithm that takes a database and returns some result.
		The guarantee states that for two neighboring databases (that differ in exactly one record), the probability that the adversary will understand by looking at the output, which of the two databases was used as an input, is bounded.
		More formally, the \acrlong{dp} is defined in \cref{definition:dp}.

		\begin{definition}[\acrlong{dp}, adapted from \cite{our-data-ourselves, differential-privacy-original}]\label{definition:dp}
			A randomized algorithm \algo{A} is $(\epsilon, \delta)$-differentially private if for all $\database_1 \sim \database_2 \in \searchKeyDomain^\dataSize$, and for all subsets $\mathcal{O}$ of the output space of \algo{A},
			\[
				\probability{ \algo{A}{ \database_1 } \in \mathcal{O} } \leq \exp(\epsilon) \cdot \probability{ \algo{A}{ \database_2 } \in \mathcal{O} } + \delta \; .
			\]
		\end{definition}

		One way to interpret this definition is the following.
		Probabilities are taken over the coins of algorithm \algo{A}, which answers a query based on a dataset.
		A natural instantiation of \algo{A} is a view of a distinguishing adversary \adversary{}, who tries to guess which of the two datasets was used.
		The expression in \cref{definition:dp} then bounds the advantage of \adversary{} with $\epsilon$ and $\delta$ parameters.
		Note that $\exp( x ) \approx 1 + x + \frac{x^2}{2!}$ and for sufficiently small $x$ the last term is negligible.
		If we put $\epsilon + 1$ in place of $\exp( \epsilon )$, it becomes clear that $\epsilon$ is the exact value by which two probabilities are allowed to differ.
		For $\epsilon = 0$, they have to be equal, for $\epsilon = 0.01$, probabilities may differ by \SI{1}{\percent}.
		Therefore, $\epsilon$ is called \emph{a privacy budget} of a \acrshort{dp} system.
		$\delta$ term is additive and therefore must be small by itself.
		This term is essentially a probability that the entire system fails.
		For example, if \algo{A} is a randomized algorithm that fails with a certain chance, this probability will be $\delta$.
		For instance, a PathORAM \cite{path-oram} algorithm can have a stash overflow with a bounded probability \cite[Theorem 1]{path-oram} and it will cause the entire algorithm to fail.
		If PathORAM is used in a \acrshort{dp} system then this probability, however small, bounded and negligible, will have to be accounted for in $\delta$.

		Note that \cref{definition:dp} describes a property of \algo{A} and not a construction method.
		To construct \algo{A}, the seminal \cite{differential-privacy-original} offers an algorithm called \acrfull{lpa}.
		The idea is to tune the noise sampled from the Laplacian distribution to the \emph{sensitivity} of a query, defined as the change of output with respect to change in input.
		For example, if a change in one record of the dataset causes a change in the output value of at most one (e.g., a count query), then the sensitivity is 1.
		\cite{differential-privacy-original} proves that if one adds $\algo{Laplace}{0, \frac{\mathsf{sensitivity}}{\epsilon}}$ to the real result of a query, the resulting mechanism is $\epsilon$-\acrshort{dp}.

		\subsection{\texorpdfstring{\acrshort{dp}}{DP} sanitizers}

			Lastly, instead of generating and adding noise each query, it is possible to generate noisy values once, embed them into the data and release the sanitized data without compromising privacy guarantees.
			The intuition is that once the noise is embedded in the dataset, the adversary can run a regular query over it and the entire query will still be \acrshort{dp}.
			Such methods are collectively called \emph{sanitization}, and there are known bounds for point and range queries, for pure ($\delta = 0$) and approximate ($\delta > 0$) \acrshort{dp} \cite{bounds-on-sample-complexity,private-learning-and-sanitization,non-interactive-database-privacy,dp-under-observation,dp-release,privately-learning-thresholds}.

		\section{\texorpdfstring{\acrlongpl{tee}}{Trusted Execution Environments}}
