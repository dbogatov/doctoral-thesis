As organizations struggle with processing vast amounts of information, outsourcing sensitive data to third parties becomes necessary.
Various cryptographic techniques are used in outsourced database systems to ensure data privacy while allowing for efficient querying.
This thesis proposes a definition and components of a new secure and efficient outsourced database system, which answers various types of queries, with different privacy guarantees in different security models.

This work starts with the survey of five order-preserving and order-revealing encryption schemes that can be used directly in many database indices, such as the B+ tree, and five range query protocols with various tradeoffs in terms of security and efficiency.
The survey systematizes the state-of-the-art range query solutions in a snapshot adversary setting and offers some non-obvious observations regarding the efficiency of the constructions.

The thesis then proceeds with \epsolute{} --- an efficient range query engine in a persistent adversary model.
In \epsolute{}, security is achieved in a setting with a much stronger adversary where she can continuously observe everything on the server, and leaking even the result size can enable a reconstruction attack.
\epsolute{} proposes a definition, construction, analysis, and experimental evaluation of a system that provably hides both access pattern and communication volume while remaining efficient.

The dissertation concludes with the analysis of secure \acrlong{knn} queries, in which the security is achieved similarly to \acrshort{ope}/\acrshort{ore} solutions --- encrypting the input with an approximate \acrlong{dcpe} scheme so that the inputs are perturbed, but the query algorithm still produces accurate results.
In the analysis, we adapt and run a series of experiments to observe the tradeoff between search accuracy and attack effectiveness.
We use \acrshort{trec} datasets and queries for the search and track the accuracy metrics such as \acrshort{mrr} and \acrshort{dcg}.
For the attacks, we build an \acrshort{lstm} model that trains on the correlation between a sentence and its embedding and then predicts words from the embedding.
